package scraper

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"path/filepath"
	"regexp"
	"runtime"
	"strings"
	"sync"
	"time"

	"dark-deep-new-tool/pkg/flaresolverr"
	"dark-deep-new-tool/pkg/models"

	"github.com/PuerkitoBio/goquery"
	"github.com/chromedp/chromedp"
	zlog "github.com/rs/zerolog/log"
)

const (
	// Timeout ayarlarÄ±
	normalTimeout = 10 * time.Second
	onionTimeout  = 180 * time.Second
	maxRetries    = 3

	// Paralel bekleme ayarlarÄ±
	elementPollInterval = 300 * time.Millisecond
	maxElementWait      = 30 * time.Second
	maxElementWaitOnion = 60 * time.Second
	logInterval         = 10 * time.Second

	// Minimum iÃ§erik uzunluÄŸu
	minContentLength = 50
)

// Cloudflare tespit pattern'leri
var cloudflarePatterns = []string{
	"checking your browser",
	"just a moment",
	"cloudflare",
	"ray id:",
	"cf-browser-verification",
	"challenge-platform",
	"turnstile",
	"gÃ¼venliÄŸini gÃ¶zden geÃ§irmesi",
	"insan olduÄŸunuzu doÄŸrulayÄ±n",
}

// Whitespace temizleme regex'i
var multipleSpaceRegex = regexp.MustCompile(`[\s\t\n\r]+`)
var multipleNewlineRegex = regexp.MustCompile(`\n{2,}`)

// Scraper web scraping iÅŸlemlerini yÃ¶netir
type Scraper struct {
	TorClient      *http.Client
	normalBrowser  context.Context
	onionBrowser   context.Context
	normalCancel   context.CancelFunc
	onionCancel    context.CancelFunc
	flareClient    *flaresolverr.Client
	flareAvailable bool
	
	// âœ… YENÄ°: Browser auto-restart iÃ§in
	scrapeCount  int64
	restartMutex sync.Mutex
	restartLimit int
}

// âœ… YENÄ°: buildChromeOptions ortak Chrome ayarlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (kod tekrarÄ±nÄ± Ã¶nler)
func buildChromeOptions() []chromedp.ExecAllocatorOption {
	return []chromedp.ExecAllocatorOption{
		chromedp.NoFirstRun,
		chromedp.NoDefaultBrowserCheck,
		chromedp.Flag("headless", true),
		chromedp.Flag("disable-gpu", true),
		chromedp.Flag("no-sandbox", true),
		chromedp.Flag("disable-dev-shm-usage", true),
		chromedp.Flag("disable-setuid-sandbox", true),
		chromedp.Flag("disable-blink-features", "AutomationControlled"),
		chromedp.Flag("exclude-switches", "enable-automation"),
		chromedp.Flag("disable-infobars", true),
		chromedp.Flag("disable-background-networking", false),
		chromedp.Flag("enable-features", "NetworkService,NetworkServiceInProcess"),
		chromedp.Flag("disable-background-timer-throttling", true),
		chromedp.Flag("disable-backgrounding-occluded-windows", true),
		chromedp.Flag("disable-breakpad", true),
		chromedp.Flag("disable-component-extensions-with-background-pages", true),
		chromedp.Flag("disable-component-update", true),
		chromedp.Flag("disable-default-apps", true),
		chromedp.Flag("disable-extensions", true),
		chromedp.Flag("disable-hang-monitor", true),
		chromedp.Flag("disable-ipc-flooding-protection", true),
		chromedp.Flag("disable-popup-blocking", true),
		chromedp.Flag("disable-prompt-on-repost", true),
		chromedp.Flag("disable-renderer-backgrounding", true),
		chromedp.Flag("disable-sync", true),
		chromedp.Flag("force-color-profile", "srgb"),
		chromedp.Flag("metrics-recording-only", true),
		chromedp.Flag("safebrowsing-disable-auto-update", true),
		chromedp.Flag("disable-web-security", false),
		chromedp.Flag("disable-webgl", false),
		chromedp.Flag("disable-reading-from-canvas", false),
		chromedp.UserAgent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"),
		chromedp.WindowSize(1920, 1080),
	}
}

// NewScraperWithBrowsers tek chrome, Ã§oklu sekme ile scraper oluÅŸturur
func NewScraperWithBrowsers(torClient *http.Client) *Scraper {
	// âœ… GÃœNCELLENDÄ°: Helper fonksiyon kullanÄ±lÄ±yor
	normalAllocOpts := buildChromeOptions()
	normalAllocCtx, _ := chromedp.NewExecAllocator(context.Background(), normalAllocOpts...)
	normalBrowser, normalCancel := chromedp.NewContext(normalAllocCtx, chromedp.WithLogf(func(string, ...interface{}) {}))

	// âœ… GÃœNCELLENDÄ°: Helper fonksiyon kullanÄ±lÄ±yor
	onionAllocOpts := append(buildChromeOptions(), chromedp.ProxyServer("socks5://127.0.0.1:9150"))
	onionAllocCtx, _ := chromedp.NewExecAllocator(context.Background(), onionAllocOpts...)
	onionBrowser, onionCancel := chromedp.NewContext(onionAllocCtx, chromedp.WithLogf(func(string, ...interface{}) {}))

	flareClient := flaresolverr.NewClient()
	flareAvailable := flareClient.IsAvailable()

	if flareAvailable {
		zlog.Info().Msg("ğŸ›¡ï¸ FlareSolverr aktif - Cloudflare bypass hazÄ±r")
	} else {
		zlog.Warn().Msg("âš ï¸ FlareSolverr eriÅŸilemez - Cloudflare korumalÄ± siteler atlanacak")
	}

	zlog.Info().Msg("ğŸŒ 2 Chrome browser baÅŸlatÄ±ldÄ± (Stealth Mode)")
	zlog.Info().Msg("âš¡ Optimizasyon: Paralel yÃ¼kleme + Cloudflare detection aktif")

	return &Scraper{
		TorClient:      torClient,
		normalBrowser:  normalBrowser,
		onionBrowser:   onionBrowser,
		normalCancel:   normalCancel,
		onionCancel:    onionCancel,
		flareClient:    flareClient,
		flareAvailable: flareAvailable,
		scrapeCount:    0,   // âœ… YENÄ°
		restartLimit:   100, // âœ… YENÄ°: Her 100 scrape'te restart
	}
}

// Close tÃ¼m browser'larÄ± kapatÄ±r
func (s *Scraper) Close() {
	zlog.Info().Msg("ğŸ§¹ Browser'lar kapatÄ±lÄ±yor...")

	if s.normalCancel != nil {
		s.normalCancel()
		zlog.Info().Msg("âœ… Normal browser kapatÄ±ldÄ±")
	}

	if s.onionCancel != nil {
		s.onionCancel()
		zlog.Info().Msg("âœ… Onion browser kapatÄ±ldÄ±")
	}
}

// Scrape forumdan veri Ã§eker
func (s *Scraper) Scrape(entry models.ForumEntry, cwd string) (models.Forum, error) {
	// âœ… YENÄ°: Browser restart kontrolÃ¼
	if s.incrementScrapeCount() {
		if err := s.restartBrowsers(); err != nil {
			zlog.Error().Err(err).Msg("âŒ Browser restart baÅŸarÄ±sÄ±z")
		}
	}

	forum := models.Forum{
		Source: entry.URL,
	}

	timeout := normalTimeout
	if entry.IsOnion {
		timeout = onionTimeout
		zlog.Info().Str("forum", entry.Name).Msg("ğŸ§… Tor modu aktif")
	}

	var lastErr error
	for attempt := 1; attempt <= maxRetries; attempt++ {
		startTime := time.Now()

		zlog.Info().
			Str("forum", entry.Name).
			Int("deneme", attempt).
			Msg("ğŸ”„ Tarama baÅŸlatÄ±lÄ±yor")

		tabCtx, tabCancel := s.createTab(entry.IsOnion, timeout)
		content, author, link, err := s.performScrape(tabCtx, entry, cwd)
		tabCancel()

		elapsed := time.Since(startTime)

		if err == nil && content != "" {
			forum.Content = content
			forum.Author = author
			forum.Link = link

			zlog.Info().
				Str("forum", entry.Name).
				Int("uzunluk", len(content)).
				Dur("sÃ¼re", elapsed).
				Msg("âœ… Veri baÅŸarÄ±yla Ã§ekildi")

			return forum, nil
		}

		lastErr = err
		zlog.Warn().
			Err(err).
			Str("forum", entry.Name).
			Int("deneme", attempt).
			Dur("sÃ¼re", elapsed).
			Msg("âš ï¸ Deneme baÅŸarÄ±sÄ±z")

		if attempt < maxRetries {
			wait := time.Duration(5*attempt) * time.Second
			zlog.Info().Dur("bekleme", wait).Msg("â³ Yeniden deneme Ã¶ncesi bekleme")
			time.Sleep(wait)
		}
	}

	zlog.Error().Err(lastErr).Str("forum", entry.Name).Msg("âŒ Tarama baÅŸarÄ±sÄ±z")
	return forum, fmt.Errorf("tÃ¼m denemeler baÅŸarÄ±sÄ±z: %v", lastErr)
}

// createTab yeni bir tab oluÅŸturur
func (s *Scraper) createTab(isOnion bool, timeout time.Duration) (context.Context, context.CancelFunc) {
	var baseBrowser context.Context

	if isOnion {
		baseBrowser = s.onionBrowser
	} else {
		baseBrowser = s.normalBrowser
	}

	tabCtx, tabCancel := chromedp.NewContext(baseBrowser)
	ctx, timeoutCancel := context.WithTimeout(tabCtx, timeout)

	combinedCancel := func() {
		timeoutCancel()
		tabCancel()
	}

	return ctx, combinedCancel
}

// injectStealthScripts bot detection'Ä± atlatmak iÃ§in script inject eder
func (s *Scraper) injectStealthScripts(ctx context.Context) {
	stealth := `
		Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
		Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
		Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en', 'tr']});
		window.chrome = {runtime: {}, loadTimes: function() {}, csi: function() {}, app: {}};
		const originalQuery = window.navigator.permissions.query;
		window.navigator.permissions.query = (parameters) => (
			parameters.name === 'notifications' ?
				Promise.resolve({ state: Notification.permission }) :
				originalQuery(parameters)
		);
	`
	chromedp.Run(ctx, chromedp.Evaluate(stealth, nil))
}

// isCloudflareChallenge HTML iÃ§eriÄŸinde Cloudflare challenge olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
func (s *Scraper) isCloudflareChallenge(html string) bool {
	htmlLower := strings.ToLower(html)
	for _, pattern := range cloudflarePatterns {
		if strings.Contains(htmlLower, pattern) {
			return true
		}
	}
	return false
}
// âœ… ESKÄ° HALÄ°NE GERÄ° DÃ–N (Fallback logic'siz)
func (s *Scraper) performScrape(ctx context.Context, entry models.ForumEntry, cwd string) (string, string, string, error) {
	s.injectStealthScripts(ctx)

	found, html, err := s.loadPageAndWaitElement(ctx, entry)

	if err != nil || !found {
		if html != "" && s.isCloudflareChallenge(html) {
			zlog.Info().
				Str("forum", entry.Name).
				Msg("ğŸ›¡ï¸ Cloudflare tespit edildi, FlareSolverr deneniyor...")

			return s.scrapeWithFlareSolverr(ctx, entry, cwd)
		}

		s.saveFailure(ctx, entry.Name, cwd)
		return "", "", "", fmt.Errorf("element bulunamadÄ±: %s - %v", entry.CSSSelector, err)
	}

	content, err := s.extractContent(ctx, entry.CSSSelector)
	if err != nil || content == "" {
		var currentHTML string
		chromedp.Run(ctx, chromedp.OuterHTML("html", &currentHTML))
		if s.isCloudflareChallenge(currentHTML) {
			zlog.Info().
				Str("forum", entry.Name).
				Msg("ğŸ›¡ï¸ Cloudflare tespit edildi (iÃ§erik Ã§ekme aÅŸamasÄ±nda)")

			return s.scrapeWithFlareSolverr(ctx, entry, cwd)
		}

		s.saveFailure(ctx, entry.Name, cwd)
		return "", "", "", fmt.Errorf("iÃ§erik Ã§ekilemedi: %w", err)
	}

	content = cleanContent(content)
	author := s.extractMetadata(ctx, fmt.Sprintf("%s .username", entry.CSSSelector))
	link := s.extractLink(ctx, entry.CSSSelector)

	return content, author, link, nil
}




func (s *Scraper) scrapeWithFlareSolverr(ctx context.Context, entry models.ForumEntry, cwd string) (string, string, string, error) {
	if !s.flareAvailable {
		return "", "", "", fmt.Errorf("FlareSolverr kullanÄ±lamÄ±yor, Cloudflare korumalÄ± site atlanÄ±yor")
	}

	resp, err := s.flareClient.GetPage(ctx, entry.URL)
	if err != nil {
		return "", "", "", fmt.Errorf("FlareSolverr hatasÄ±: %w", err)
	}

	html := resp.Solution.Response
	if html == "" {
		return "", "", "", fmt.Errorf("FlareSolverr boÅŸ HTML dÃ¶ndÃ¼")
	}

	content, author, link := s.parseHTMLContent(html, entry.CSSSelector)

	if content == "" {
		s.saveHTMLForDebug(html, entry.Name, cwd)
		return "", "", "", fmt.Errorf("FlareSolverr HTML'inden iÃ§erik Ã§Ä±karÄ±lamadÄ±")
	}

	zlog.Info().
		Str("forum", entry.Name).
		Int("uzunluk", len(content)).
		Msg("âœ… FlareSolverr ile veri Ã§ekildi")

	return content, author, link, nil
}

// cleanContent iÃ§erikteki gereksiz whitespace'leri temizler
func cleanContent(content string) string {
	content = multipleSpaceRegex.ReplaceAllString(content, " ")
	content = multipleNewlineRegex.ReplaceAllString(content, "\n")
	content = strings.TrimSpace(content)

	lines := strings.Split(content, "\n")
	var cleanedLines []string
	for _, line := range lines {
		trimmed := strings.TrimSpace(line)
		if trimmed != "" {
			cleanedLines = append(cleanedLines, trimmed)
		}
	}

	return strings.Join(cleanedLines, "\n")
}

// isValidContent iÃ§eriÄŸin geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
func isValidContent(content string) bool {
	if len(content) < minContentLength {
		return false
	}

	onlyNumbersSpaces := regexp.MustCompile(`^[\d\s\n]+$`)
	if onlyNumbersSpaces.MatchString(content) {
		return false
	}

	navPatterns := []string{
		"next", "previous", "page", "first", "last",
		"ileri", "geri", "sayfa", "Ã¶nceki", "sonraki",
	}
	contentLower := strings.ToLower(content)
	navCount := 0
	words := strings.Fields(contentLower)
	for _, word := range words {
		for _, pattern := range navPatterns {
			if word == pattern {
				navCount++
			}
		}
	}
	if len(words) > 0 && float64(navCount)/float64(len(words)) > 0.5 {
		return false
	}

	return true
}

// parseHTMLContent HTML string'inden iÃ§erik Ã§Ä±karÄ±r (goquery ile)
func (s *Scraper) parseHTMLContent(html, selector string) (content, author, link string) {
	doc, err := goquery.NewDocumentFromReader(strings.NewReader(html))
	if err != nil {
		zlog.Warn().Err(err).Msg("HTML parse hatasÄ±")
		return "", "", ""
	}

	threadSelectors := []string{
		"div.structItem--thread",
		"div.structItem-title",
		"li.discussionListItem",
		".discussionList .discussionListItem",
		"tr.inline_row",
		"tr.forumdisplay_regular",
		"div.thread_list_item",
		".tborder tr",
		"li.threadbit",
		"div.threadbit",
		".threads .thread",
		"li.ipsDataItem",
		"div.cTopicList",
		"article.thread",
		"div.thread-item",
		"div.topic-item",
		".thread-row",
		".topic-row",
	}

	var selection *goquery.Selection
	var usedSelector string

	simpleSelector := simplifySelector(selector)
	selection = doc.Find(simpleSelector).First()

	if selection.Length() > 0 {
		usedSelector = simpleSelector
	} else {
		for _, altSelector := range threadSelectors {
			selection = doc.Find(altSelector).First()
			if selection.Length() > 0 {
				usedSelector = altSelector
				zlog.Info().
					Str("selector", altSelector).
					Msg("âœ… Alternatif selector ile element bulundu")
				break
			}
		}
	}

	if selection == nil || selection.Length() == 0 {
		zlog.Warn().Msg("HiÃ§bir selector ile element bulunamadÄ±")
		return "", "", ""
	}

	titleSelectors := []string{
		".structItem-title a",
		".subject_new a",
		".subject_old a",
		".threadtitle a",
		".title a",
		"a.topictitle",
		"h3 a",
		"h4 a",
		".thread-title a",
		"a[href*='thread']",
		"a[href*='topic']",
		"a[href*='Thread']",
	}

	var title string
	for _, titleSel := range titleSelectors {
		titleEl := selection.Find(titleSel).First()
		if titleEl.Length() > 0 {
			title = strings.TrimSpace(titleEl.Text())
			if title != "" && len(title) > 10 {
				break
			}
		}
	}

	if title == "" {
		title = selection.Text()
	}

	content = cleanContent(title)

	if !isValidContent(content) {
		zlog.Warn().
			Str("content_preview", truncateString(content, 50)).
			Msg("Ä°Ã§erik geÃ§ersiz (pagination veya nav olabilir)")

		selection = doc.Find(usedSelector).Eq(1)
		if selection.Length() > 0 {
			for _, titleSel := range titleSelectors {
				titleEl := selection.Find(titleSel).First()
				if titleEl.Length() > 0 {
					title = strings.TrimSpace(titleEl.Text())
					if title != "" && len(title) > 10 {
						break
					}
				}
			}
			if title == "" {
				title = selection.Text()
			}
			content = cleanContent(title)
		}
	}

	linkSelectors := []string{
		"a[href*='thread']",
		"a[href*='topic']",
		"a[href*='Thread']",
		".structItem-title a",
		".subject_new a",
		".threadtitle a",
		"a",
	}

	for _, linkSel := range linkSelectors {
		linkEl := selection.Find(linkSel).First()
		if linkEl.Length() > 0 {
			link, _ = linkEl.Attr("href")
			if link != "" && !strings.HasPrefix(link, "#") && !strings.Contains(link, "page=") {
				break
			}
		}
	}

	authorSelectors := []string{
		".username",
		".author",
		".posterdate a",
		".message-name a",
		".structItem-minor a",
		"a[href*='member']",
		"a[href*='user']",
		".poster a",
	}

	for _, authorSel := range authorSelectors {
		authorEl := selection.Find(authorSel).First()
		if authorEl.Length() > 0 {
			author = strings.TrimSpace(authorEl.Text())
			if author != "" && len(author) > 1 {
				break
			}
		}
	}

	zlog.Debug().
		Str("selector", usedSelector).
		Int("content_len", len(content)).
		Str("link", link).
		Str("author", author).
		Msg("HTML parse sonucu")

	return content, author, link
}

// simplifySelector karmaÅŸÄ±k CSS selector'Ä± basitleÅŸtirir
func simplifySelector(selector string) string {
	result := selector

	for strings.Contains(result, ":nth-child") {
		start := strings.Index(result, ":nth-child")
		end := strings.Index(result[start:], ")")
		if end != -1 {
			result = result[:start] + result[start+end+1:]
		} else {
			break
		}
	}

	result = strings.ReplaceAll(result, " > ", " ")
	result = strings.ReplaceAll(result, ">", " ")

	for strings.Contains(result, "  ") {
		result = strings.ReplaceAll(result, "  ", " ")
	}

	return strings.TrimSpace(result)
}

// truncateString string'i belirtilen uzunlukta keser
func truncateString(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}

// loadPageAndWaitElement sayfa yÃ¼klerken aynÄ± anda element arar (PARALEL)
func (s *Scraper) loadPageAndWaitElement(ctx context.Context, entry models.ForumEntry) (bool, string, error) {
	startTime := time.Now()

	maxWait := maxElementWait
	if entry.IsOnion {
		maxWait = maxElementWaitOnion
	}

	zlog.Info().
		Str("url", entry.URL).
		Dur("max_sÃ¼re", maxWait).
		Msg("ğŸš€ Paralel yÃ¼kleme baÅŸlatÄ±ldÄ±")

	navigateDone := make(chan error, 1)
	go func() {
		err := chromedp.Run(ctx, chromedp.Navigate(entry.URL))
		navigateDone <- err
	}()

	deadline := time.Now().Add(maxWait)
	query := fmt.Sprintf(`document.querySelectorAll('%s').length`, entry.CSSSelector)

	var lastLogTime time.Time
	attemptCount := 0
	elementFound := false
	var pageHTML string

	time.Sleep(2 * time.Second)
	s.injectStealthScripts(ctx)

	for time.Now().Before(deadline) {
		attemptCount++

		var count int
		err := chromedp.Run(ctx, chromedp.Evaluate(query, &count))

		if err == nil && count > 0 {
			elementFound = true
			zlog.Info().
				Int("element_sayÄ±sÄ±", count).
				Int("deneme", attemptCount).
				Dur("sÃ¼re", time.Since(startTime)).
				Msg("âœ… Element bulundu")
			break
		}

		if attemptCount%10 == 0 {
			chromedp.Run(ctx, chromedp.OuterHTML("html", &pageHTML))
			if s.isCloudflareChallenge(pageHTML) {
				zlog.Debug().Msg("ğŸ›¡ï¸ Cloudflare challenge tespit edildi")
				return false, pageHTML, fmt.Errorf("cloudflare challenge")
			}
		}

		if time.Since(lastLogTime) >= logInterval {
			elapsed := time.Since(startTime)
			remaining := maxWait - elapsed
			zlog.Debug().
				Dur("geÃ§en", elapsed).
				Dur("kalan", remaining).
				Int("deneme", attemptCount).
				Msg("â³ Element aranÄ±yor...")
			lastLogTime = time.Now()
		}

		time.Sleep(elementPollInterval)
	}

	select {
	case navErr := <-navigateDone:
		if navErr != nil && !strings.Contains(navErr.Error(), "timeout") {
			zlog.Debug().Err(navErr).Msg("Navigate tamamlandÄ±")
		}
	default:
	}

	totalTime := time.Since(startTime)

	if !elementFound {
		chromedp.Run(ctx, chromedp.OuterHTML("html", &pageHTML))

		zlog.Warn().
			Str("selector", entry.CSSSelector).
			Int("toplam_deneme", attemptCount).
			Dur("toplam_sÃ¼re", totalTime).
			Msg("âŒ Element bulunamadÄ± (timeout)")
		return false, pageHTML, fmt.Errorf("element %v sÃ¼rede bulunamadÄ±", maxWait)
	}

	zlog.Info().
		Dur("toplam_sÃ¼re", totalTime).
		Msg("ğŸ YÃ¼kleme tamamlandÄ±")

	return true, "", nil
}

// extractContent iÃ§eriÄŸi Ã§eker
func (s *Scraper) extractContent(ctx context.Context, selector string) (string, error) {
	var content string

	if err := chromedp.Run(ctx,
		chromedp.Text(selector, &content, chromedp.ByQuery, chromedp.NodeVisible),
	); err == nil && content != "" {
		return strings.TrimSpace(content), nil
	}

	query := fmt.Sprintf(`document.querySelector('%s')?.innerText || ''`, selector)
	if err := chromedp.Run(ctx, chromedp.Evaluate(query, &content)); err == nil && content != "" {
		return strings.TrimSpace(content), nil
	}

	query = fmt.Sprintf(`document.querySelector('%s')?.textContent || ''`, selector)
	if err := chromedp.Run(ctx, chromedp.Evaluate(query, &content)); err == nil && content != "" {
		return strings.TrimSpace(content), nil
	}

	return "", fmt.Errorf("iÃ§erik Ã§ekilemedi")
}

// extractMetadata metadata Ã§eker
func (s *Scraper) extractMetadata(ctx context.Context, selector string) string {
	var data string
	chromedp.Run(ctx, chromedp.Text(selector, &data, chromedp.ByQuery))
	return strings.TrimSpace(data)
}

// extractLink link Ã§eker (Ã§oklu yÃ¶ntem ile)
func (s *Scraper) extractLink(ctx context.Context, selector string) string {
	var link string

	query := fmt.Sprintf(`document.querySelector('%s a')?.getAttribute('href') || ''`, selector)
	if err := chromedp.Run(ctx, chromedp.Evaluate(query, &link)); err == nil && link != "" {
		return link
	}

	query = fmt.Sprintf(`document.querySelector('%s')?.getAttribute('href') || ''`, selector)
	if err := chromedp.Run(ctx, chromedp.Evaluate(query, &link)); err == nil && link != "" {
		return link
	}

	query = fmt.Sprintf(`document.querySelector('%s')?.getAttribute('data-href') || document.querySelector('%s a')?.getAttribute('data-href') || ''`, selector, selector)
	if err := chromedp.Run(ctx, chromedp.Evaluate(query, &link)); err == nil && link != "" {
		return link
	}

	chromedp.Run(ctx, chromedp.AttributeValue(fmt.Sprintf("%s a", selector), "href", &link, nil, chromedp.ByQuery))

	return link
}

// saveFailure hata diagnostics kaydeder
func (s *Scraper) saveFailure(ctx context.Context, forumName string, cwd string) {
	timestamp := time.Now().Format("2006-01-02_15-04-05")
	failureDir := filepath.Join(cwd, "output", "failure")

	if err := os.MkdirAll(failureDir, 0755); err != nil {
		return
	}

	var buf []byte
	if err := chromedp.Run(ctx, chromedp.FullScreenshot(&buf, 90)); err == nil && len(buf) > 0 {
		path := filepath.Join(failureDir, fmt.Sprintf("%s_%s.png", forumName, timestamp))
		os.WriteFile(path, buf, 0644)
		zlog.Debug().Str("dosya", filepath.Base(path)).Msg("ğŸ”§ Failure screenshot kaydedildi")
	}

	var html string
	if err := chromedp.Run(ctx, chromedp.OuterHTML("html", &html)); err == nil && html != "" {
		path := filepath.Join(failureDir, fmt.Sprintf("%s_%s.html", forumName, timestamp))
		os.WriteFile(path, []byte(html), 0644)
		zlog.Debug().Str("dosya", filepath.Base(path)).Msg("ğŸ”§ Failure HTML kaydedildi")
	}
}

// saveHTMLForDebug FlareSolverr HTML'ini debug iÃ§in kaydeder
func (s *Scraper) saveHTMLForDebug(html, forumName, cwd string) {
	timestamp := time.Now().Format("2006-01-02_15-04-05")
	debugDir := filepath.Join(cwd, "output", "debug")

	if err := os.MkdirAll(debugDir, 0755); err != nil {
		return
	}

	path := filepath.Join(debugDir, fmt.Sprintf("%s_flare_%s.html", forumName, timestamp))
	os.WriteFile(path, []byte(html), 0644)
	zlog.Debug().Str("dosya", filepath.Base(path)).Msg("ğŸ”§ FlareSolverr HTML kaydedildi")
}

// âœ… YENÄ°: incrementScrapeCount scrape sayÄ±sÄ±nÄ± artÄ±rÄ±r ve restart gerekip gerekmediÄŸini dÃ¶ner
func (s *Scraper) incrementScrapeCount() bool {
	s.restartMutex.Lock()
	defer s.restartMutex.Unlock()

	s.scrapeCount++

	if s.scrapeCount >= int64(s.restartLimit) {
		s.scrapeCount = 0
		return true
	}

	return false
}

// âœ… YENÄ°: restartBrowsers browser'larÄ± kapat-aÃ§ (memory temizliÄŸi)
func (s *Scraper) restartBrowsers() error {
	zlog.Info().
		Int("limit", s.restartLimit).
		Msg("ğŸ”„ Browser restart baÅŸlatÄ±lÄ±yor (memory cleanup)")

	if s.normalCancel != nil {
		s.normalCancel()
	}
	if s.onionCancel != nil {
		s.onionCancel()
	}

	time.Sleep(2 * time.Second)

	normalAllocOpts := buildChromeOptions()
	normalAllocCtx, _ := chromedp.NewExecAllocator(context.Background(), normalAllocOpts...)
	s.normalBrowser, s.normalCancel = chromedp.NewContext(normalAllocCtx, chromedp.WithLogf(func(string, ...interface{}) {}))

	onionAllocOpts := append(buildChromeOptions(), chromedp.ProxyServer("socks5://127.0.0.1:9150"))
	onionAllocCtx, _ := chromedp.NewExecAllocator(context.Background(), onionAllocOpts...)
	s.onionBrowser, s.onionCancel = chromedp.NewContext(onionAllocCtx, chromedp.WithLogf(func(string, ...interface{}) {}))

	zlog.Info().Msg("âœ… Browser restart tamamlandÄ±")

	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	zlog.Info().
		Uint64("alloc_mb", m.Alloc/1024/1024).
		Uint64("sys_mb", m.Sys/1024/1024).
		Msg("ğŸ“Š Restart sonrasÄ± memory")

	return nil
}